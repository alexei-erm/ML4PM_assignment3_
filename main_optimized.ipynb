{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *\n",
    "from training import *\n",
    "from data_processing import *\n",
    "\n",
    "import importlib\n",
    "import imports\n",
    "importlib.reload(imports)\n",
    "\n",
    "device = 'mps'\n",
    "model_name = 'optimized'\n",
    "\n",
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ccLNkIa9Xvx",
    "outputId": "1dd1e3d4-4587-46f1-871e-f72159be57c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexei.ermochkine/Desktop/ma5/ML4PM/assignment_3_graded/ML4PM_assignment3/ncmapps_ds02.csv\n"
     ]
    }
   ],
   "source": [
    "folder = os.getcwd()\n",
    "filename = f'{folder}/ncmapps_ds02.csv'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Au1CJA3b95-f",
    "outputId": "b873d351-3e30-4240-d04e-c24c4ffc9520"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T48</th>\n",
       "      <th>T50</th>\n",
       "      <th>P15</th>\n",
       "      <th>P2</th>\n",
       "      <th>P21</th>\n",
       "      <th>P24</th>\n",
       "      <th>Ps30</th>\n",
       "      <th>P40</th>\n",
       "      <th>...</th>\n",
       "      <th>Wf</th>\n",
       "      <th>alt</th>\n",
       "      <th>Mach</th>\n",
       "      <th>TRA</th>\n",
       "      <th>T2</th>\n",
       "      <th>RUL</th>\n",
       "      <th>Fc</th>\n",
       "      <th>unit</th>\n",
       "      <th>hs</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593.28656</td>\n",
       "      <td>1422.0460</td>\n",
       "      <td>1797.2323</td>\n",
       "      <td>1214.0819</td>\n",
       "      <td>15.626362</td>\n",
       "      <td>11.445379</td>\n",
       "      <td>15.864327</td>\n",
       "      <td>19.897537</td>\n",
       "      <td>327.51962</td>\n",
       "      <td>332.79700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811431</td>\n",
       "      <td>9889.289</td>\n",
       "      <td>0.443401</td>\n",
       "      <td>76.022545</td>\n",
       "      <td>496.67758</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593.30220</td>\n",
       "      <td>1422.3720</td>\n",
       "      <td>1797.9927</td>\n",
       "      <td>1214.1847</td>\n",
       "      <td>15.607640</td>\n",
       "      <td>11.424822</td>\n",
       "      <td>15.845321</td>\n",
       "      <td>19.881628</td>\n",
       "      <td>327.48330</td>\n",
       "      <td>332.75565</td>\n",
       "      <td>...</td>\n",
       "      <td>3.812693</td>\n",
       "      <td>9951.729</td>\n",
       "      <td>0.444472</td>\n",
       "      <td>76.222015</td>\n",
       "      <td>496.53890</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593.14215</td>\n",
       "      <td>1421.8730</td>\n",
       "      <td>1797.1808</td>\n",
       "      <td>1213.5430</td>\n",
       "      <td>15.581609</td>\n",
       "      <td>11.407368</td>\n",
       "      <td>15.818893</td>\n",
       "      <td>19.848164</td>\n",
       "      <td>326.81784</td>\n",
       "      <td>332.08163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.803472</td>\n",
       "      <td>10011.879</td>\n",
       "      <td>0.445830</td>\n",
       "      <td>76.191210</td>\n",
       "      <td>496.43396</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>592.98883</td>\n",
       "      <td>1421.4746</td>\n",
       "      <td>1796.5925</td>\n",
       "      <td>1213.0120</td>\n",
       "      <td>15.554759</td>\n",
       "      <td>11.387945</td>\n",
       "      <td>15.791634</td>\n",
       "      <td>19.814800</td>\n",
       "      <td>326.22076</td>\n",
       "      <td>331.47592</td>\n",
       "      <td>...</td>\n",
       "      <td>3.795554</td>\n",
       "      <td>10073.271</td>\n",
       "      <td>0.446986</td>\n",
       "      <td>76.196846</td>\n",
       "      <td>496.30667</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592.66296</td>\n",
       "      <td>1420.8185</td>\n",
       "      <td>1795.7623</td>\n",
       "      <td>1212.4274</td>\n",
       "      <td>15.512026</td>\n",
       "      <td>11.356153</td>\n",
       "      <td>15.748249</td>\n",
       "      <td>19.760134</td>\n",
       "      <td>325.36660</td>\n",
       "      <td>330.60760</td>\n",
       "      <td>...</td>\n",
       "      <td>3.784542</td>\n",
       "      <td>10136.359</td>\n",
       "      <td>0.446471</td>\n",
       "      <td>76.204480</td>\n",
       "      <td>496.02774</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T24        T30        T48        T50        P15         P2  \\\n",
       "0  593.28656  1422.0460  1797.2323  1214.0819  15.626362  11.445379   \n",
       "1  593.30220  1422.3720  1797.9927  1214.1847  15.607640  11.424822   \n",
       "2  593.14215  1421.8730  1797.1808  1213.5430  15.581609  11.407368   \n",
       "3  592.98883  1421.4746  1796.5925  1213.0120  15.554759  11.387945   \n",
       "4  592.66296  1420.8185  1795.7623  1212.4274  15.512026  11.356153   \n",
       "\n",
       "         P21        P24       Ps30        P40  ...        Wf        alt  \\\n",
       "0  15.864327  19.897537  327.51962  332.79700  ...  3.811431   9889.289   \n",
       "1  15.845321  19.881628  327.48330  332.75565  ...  3.812693   9951.729   \n",
       "2  15.818893  19.848164  326.81784  332.08163  ...  3.803472  10011.879   \n",
       "3  15.791634  19.814800  326.22076  331.47592  ...  3.795554  10073.271   \n",
       "4  15.748249  19.760134  325.36660  330.60760  ...  3.784542  10136.359   \n",
       "\n",
       "       Mach        TRA         T2  RUL  Fc  unit  hs  cycle  \n",
       "0  0.443401  76.022545  496.67758   74   3     2   1      1  \n",
       "1  0.444472  76.222015  496.53890   74   3     2   1      1  \n",
       "2  0.445830  76.191210  496.43396   74   3     2   1      1  \n",
       "3  0.446986  76.196846  496.30667   74   3     2   1      1  \n",
       "4  0.446471  76.204480  496.02774   74   3     2   1      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j-WToY0EQ8gJ"
   },
   "outputs": [],
   "source": [
    "LABELS = ['RUL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQUvTSv8GSeE"
   },
   "source": [
    "Operative Conditions ($w$)\n",
    "\n",
    "DASHlink- Flight Data For Tail 687.(2012). Retrieved on 2019-01-29 from https://c3.nasa.gov/dashlink/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HrHh3rYqGhGt"
   },
   "outputs": [],
   "source": [
    "W_VAR = ['alt', 'Mach', 'TRA', 'T2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQvRwIJqGN7H"
   },
   "source": [
    "Sensor readings ($X_s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PjgyPJPNGiOI"
   },
   "outputs": [],
   "source": [
    "XS_VAR = ['T24', 'T30', 'T48', 'T50', 'P15', 'P2', 'P21', 'P24', 'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 403236\tvalidation_size: 100809\ttest_size: 115274\n"
     ]
    }
   ],
   "source": [
    "# dataset parameters\n",
    "TRAIN_UNITS = [2, 5, 10, 16, 18, 20]\n",
    "TEST_UNITS = [11, 14, 15]\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    # CNN model parameters\n",
    "    'in_channels': 18, \n",
    "    'out_channels': 1,\n",
    "    'window': 50, \n",
    "    'n_ch': 10, \n",
    "    'n_k': 10, \n",
    "    'n_hidden': 50, \n",
    "    'n_layers': 3,\n",
    "    'dropout': 0.1,\n",
    "    'padding': 'same',\n",
    "    'use_batchnorm': True,\n",
    "    # training parameters\n",
    "    'batch_size': 256,  \n",
    "    'base_lr': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'max_epochs': 50\n",
    "}\n",
    "\n",
    "\n",
    "DATASETS = create_datasets(df, window_size=DEFAULT_PARAMS['window'], train_units=TRAIN_UNITS, test_units=TEST_UNITS)\n",
    "LOADERS = create_data_loaders(DATASETS, batch_size=DEFAULT_PARAMS['batch_size'], val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(seed, params=DEFAULT_PARAMS):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    model = CNN(\n",
    "        in_channels=params['in_channels'],\n",
    "        out_channels=params['out_channels'], \n",
    "        n_ch=params['n_ch'],\n",
    "        n_k=params['n_k'],\n",
    "        n_hidden=params['n_hidden'],\n",
    "        n_layers=params['n_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        padding=params['padding'],\n",
    "        use_batchnorm=params['use_batchnorm']\n",
    "    ).to(device)  # Move model to device immediately after creation\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params['base_lr'],\n",
    "        weight_decay=params['weight_decay'],\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion=criterion,\n",
    "        n_epochs=params['max_epochs'],\n",
    "        seed=seed,\n",
    "        device=device,  # Pass device to trainer\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    trainer.fit(LOADERS)\n",
    "    df_eval, df_eval_out = trainer.eval_rul_prediction(LOADERS[1])\n",
    "    df_test, df_test_out = trainer.eval_rul_prediction(LOADERS[2])\n",
    "    return df_eval, df_eval_out, df_test, df_test_out, trainer.losses4aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexei.ermochkine/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 16:28:38,156] Using an existing study with name 'batchnorm_dropout_optimization' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = DEFAULT_PARAMS.copy()\n",
    "    \n",
    "    # Architecture hyperparameters\n",
    "    params['in_channels'] = 18  # Fixed based on input features\n",
    "    params['out_channels'] = 1  # Fixed based on output\n",
    "    params['window'] = 50  # Fixed based on sequence length\n",
    "    \n",
    "    # Tune network structure\n",
    "    params['n_ch'] = trial.suggest_int('n_ch', 8, 32)  # Number of channels in conv layers\n",
    "    params['n_k'] = trial.suggest_int('n_k', 5, 15)    # Kernel size\n",
    "    params['n_hidden'] = trial.suggest_int('n_hidden', 32, 128)  # Hidden layer size\n",
    "    params['n_layers'] = trial.suggest_int('n_layers', 2, 4)     # Number of conv layers\n",
    "    \n",
    "    # Tune training parameters\n",
    "    params['base_lr'] = trial.suggest_float('base_lr', 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    # Fixed parameters\n",
    "    params['padding'] = 'same'\n",
    "    params['max_epochs'] = 50  # Could also be tuned if needed\n",
    "    \n",
    "    return evaluate_model(params)\n",
    "\n",
    "def evaluate_model(params):\n",
    "    \"\"\"Evaluate a model configuration\"\"\"\n",
    "    n_runs = 3  # Number of runs to average over\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        seed = 42 + run  # Different seed for each run\n",
    "        df_eval, df_eval_out, _, _ = run_single(seed, params)\n",
    "        rmse = df_eval_out['rmse'].values[0]\n",
    "        rmse_scores.append(rmse)\n",
    "        \n",
    "        # Early stopping if performance is very poor\n",
    "        if rmse > 15:  # You can adjust this threshold\n",
    "            return float('inf')\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# Create and run the study\n",
    "study_name = 'batchnorm_dropout_optimization'\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"minimize\",\n",
    "    storage=f'sqlite:///{folder}/batchnorm_dropout_study.db',\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# Add callback for monitoring\n",
    "def print_callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        print(f\"\\nTrial {trial.number} finished with best value: {trial.value:.4f}\")\n",
    "        print(\"Best parameters:\")\n",
    "        for key, value in study.best_trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv1d(18, 26, kernel_size=(13,), stride=(1,), padding=same)\n",
      "    (1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv1d(26, 26, kernel_size=(13,), stride=(1,), padding=same)\n",
      "    (4): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv1d(26, 26, kernel_size=(13,), stride=(1,), padding=same)\n",
      "    (7): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1300, out_features=34, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bn_fc): BatchNorm1d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=34, out_features=1, bias=True)\n",
      ")\n",
      "Training model for 50 epochs...\n",
      "[Epoch 1] train_loss = 117.05357, eval_loss = 2458.68237, test_loss = 3820.11230 [27.7s]\n",
      "[Epoch 2] train_loss = 57.88968, eval_loss = 378.51642, test_loss = 956.00177 [25.9s]\n",
      "[Epoch 3] train_loss = 53.35414, eval_loss = 336.69635, test_loss = 690.40295 [26.8s]\n",
      "[Epoch 4] train_loss = 51.42360, eval_loss = 158.88425, test_loss = 197.45975 [26.1s]\n",
      "[Epoch 5] train_loss = 49.83750, eval_loss = 69.16953, test_loss = 174.30705 [25.9s]\n",
      "[Epoch 6] train_loss = 49.70338, eval_loss = 83.97215, test_loss = 63.57219 [23.1s]\n",
      "[Epoch 7] train_loss = 47.42957, eval_loss = 41.29881, test_loss = 98.49048 [23.7s]\n",
      "[Epoch 8] train_loss = 46.02220, eval_loss = 411.47284, test_loss = 859.72839 [23.4s]\n",
      "[Epoch 9] train_loss = 46.00400, eval_loss = 48.06250, test_loss = 58.38063 [23.0s]\n",
      "[Epoch 10] train_loss = 44.72824, eval_loss = 81.00971, test_loss = 63.47443 [23.1s]\n",
      "[Epoch 11] train_loss = 43.78899, eval_loss = 602.29712, test_loss = 625.31128 [23.4s]\n",
      "[Epoch 12] train_loss = 43.46749, eval_loss = 454.31277, test_loss = 446.06256 [23.4s]\n",
      "[Epoch 13] train_loss = 42.54189, eval_loss = 372.07718, test_loss = 434.87338 [23.4s]\n",
      "[Epoch 14] train_loss = 42.39199, eval_loss = 43.86379, test_loss = 78.42850 [23.2s]\n",
      "[Epoch 15] train_loss = 41.17638, eval_loss = 115.08725, test_loss = 116.36073 [23.8s]\n",
      "[Epoch 16] train_loss = 41.09933, eval_loss = 39.21446, test_loss = 71.38299 [23.2s]\n",
      "[Epoch 17] train_loss = 40.52763, eval_loss = 207.57515, test_loss = 275.62186 [23.5s]\n",
      "[Epoch 18] train_loss = 40.10331, eval_loss = 250.01779, test_loss = 571.60535 [23.2s]\n",
      "[Epoch 19] train_loss = 39.97034, eval_loss = 147.30359, test_loss = 135.16451 [23.0s]\n",
      "[Epoch 20] train_loss = 39.70326, eval_loss = 82.90788, test_loss = 253.01579 [23.2s]\n",
      "[Epoch 21] train_loss = 39.09582, eval_loss = 34.90806, test_loss = 120.30965 [23.2s]\n",
      "[Epoch 22] train_loss = 38.60450, eval_loss = 61.95213, test_loss = 103.34841 [23.3s]\n",
      "[Epoch 23] train_loss = 38.37925, eval_loss = 494.11780, test_loss = 523.09369 [23.3s]\n",
      "[Epoch 24] train_loss = 38.10644, eval_loss = 84.27942, test_loss = 254.27031 [23.5s]\n",
      "[Epoch 25] train_loss = 37.63898, eval_loss = 136.23355, test_loss = 156.51445 [26.2s]\n",
      "[Epoch 26] train_loss = 37.39144, eval_loss = 48.99389, test_loss = 168.70787 [25.1s]\n",
      "[Epoch 27] train_loss = 37.09541, eval_loss = 137.17883, test_loss = 241.37804 [24.9s]\n",
      "[Epoch 28] train_loss = 36.59524, eval_loss = 50.14007, test_loss = 191.95221 [25.2s]\n",
      "[Epoch 29] train_loss = 36.44882, eval_loss = 71.40475, test_loss = 60.58115 [25.2s]\n",
      "[Epoch 30] train_loss = 36.17774, eval_loss = 47.61124, test_loss = 64.04213 [24.8s]\n",
      "[Epoch 31] train_loss = 35.96754, eval_loss = 96.11726, test_loss = 219.80307 [24.9s]\n",
      "[Epoch 32] train_loss = 35.71092, eval_loss = 62.55249, test_loss = 62.23212 [24.8s]\n",
      "[Epoch 33] train_loss = 35.44726, eval_loss = 101.52845, test_loss = 190.01523 [24.9s]\n",
      "[Epoch 34] train_loss = 35.40987, eval_loss = 57.78177, test_loss = 215.60690 [24.8s]\n",
      "[Epoch 35] train_loss = 34.96909, eval_loss = 133.43417, test_loss = 128.38049 [24.8s]\n",
      "[Epoch 36] train_loss = 34.81327, eval_loss = 104.32965, test_loss = 151.76039 [25.0s]\n",
      "[Epoch 37] train_loss = 34.71083, eval_loss = 52.25931, test_loss = 208.34534 [25.5s]\n",
      "[Epoch 38] train_loss = 34.34250, eval_loss = 65.58900, test_loss = 129.09390 [24.8s]\n",
      "[Epoch 39] train_loss = 34.33359, eval_loss = 41.65441, test_loss = 94.94814 [25.0s]\n",
      "[Epoch 40] train_loss = 33.91708, eval_loss = 33.01713, test_loss = 86.85592 [25.1s]\n",
      "[Epoch 41] train_loss = 33.81320, eval_loss = 193.87241, test_loss = 280.54117 [24.9s]\n",
      "[Epoch 42] train_loss = 33.49969, eval_loss = 194.94554, test_loss = 413.79108 [25.6s]\n",
      "[Epoch 43] train_loss = 33.44784, eval_loss = 276.08411, test_loss = 452.84995 [26.7s]\n",
      "[Epoch 44] train_loss = 33.34876, eval_loss = 32.18867, test_loss = 133.47089 [24.9s]\n",
      "[Epoch 45] train_loss = 32.96210, eval_loss = 35.66327, test_loss = 138.32310 [25.4s]\n",
      "[Epoch 46] train_loss = 32.98700, eval_loss = 29.75068, test_loss = 114.55724 [24.9s]\n",
      "[Epoch 47] train_loss = 32.71521, eval_loss = 98.29545, test_loss = 245.92961 [24.9s]\n",
      "[Epoch 48] train_loss = 32.83342, eval_loss = 127.38319, test_loss = 206.07024 [25.0s]\n",
      "[Epoch 49] train_loss = 32.71688, eval_loss = 93.67536, test_loss = 179.71738 [24.8s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexei.ermochkine/Desktop/ma5/ML4PM/assignment_3_graded/ML4PM_assignment3/training.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50] train_loss = 32.39606, eval_loss = 100.89209, test_loss = 125.77521 [24.8s]\n",
      "Task done in 1228s\n",
      "Evaluating test RUL...\n",
      "Model CNN saved in models_optimized/optimized_1106162902.pt loaded to mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:02<00:00, 152.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test RUL...\n",
      "Model CNN saved in models_optimized/optimized_1106162902.pt loaded to mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [00:02<00:00, 185.84it/s]\n",
      "[W 2024-11-06 16:49:36,321] Trial 1 failed with parameters: {'n_ch': 26, 'n_k': 13, 'n_hidden': 34, 'n_layers': 3, 'base_lr': 0.0037501183745495843} because of the following error: ValueError('too many values to unpack (expected 4)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexei.ermochkine/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/94/hphmcz155530jnw34qpssk100000gn/T/ipykernel_22957/2908481708.py\", line 22, in objective\n",
      "    return evaluate_model(params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/94/hphmcz155530jnw34qpssk100000gn/T/ipykernel_22957/2908481708.py\", line 31, in evaluate_model\n",
      "    df_eval, df_eval_out, _, _ = run_single(seed, params)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "[W 2024-11-06 16:49:36,322] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Adjust based on your computational budget\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print final results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStudy statistics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Desktop/ma5/ML4PM/venv4ml4pm/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     19\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Could also be tuned if needed\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[1;32m     30\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m \u001b[38;5;241m+\u001b[39m run  \u001b[38;5;66;03m# Different seed for each run\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     df_eval, df_eval_out, _, _ \u001b[38;5;241m=\u001b[39m run_single(seed, params)\n\u001b[1;32m     32\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m df_eval_out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m     rmse_scores\u001b[38;5;241m.\u001b[39mappend(rmse)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "n_trials = 2  # Adjust based on your computational budget\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[print_callback])\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nStudy statistics: \")\n",
    "print(f\"  Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"  Best trial:\")\n",
    "print(f\"    Value: {study.best_trial.value:.4f}\")\n",
    "print(\"\\n  Best parameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Visualize results\n",
    "try:\n",
    "    # Parameter importance plot\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Optimization history\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Parameter relationships\n",
    "    fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Save results to DataFrame\n",
    "results_df = study.trials_dataframe()\n",
    "results_df.to_csv(f'{folder}/batchnorm_dropout_optimization_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the study for resuming, comment out when reloading\n",
    "# study = optuna.load_study(study_name=study_name, storage=f'sqlite:///{folder}/study.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the est model parameter\n",
    "best_trial = study.best_trial\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING ON 5 SEEDS\n",
    "## reminder: CHANGE FOLDER AND MODEL_NAME IN TRAINING.PY BEFORE RUNNING !!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "device = 'mps'\n",
    "N_RUNS = 5\n",
    "\n",
    "df_list = []  \n",
    "all_df_test = []\n",
    "all_train_losses = []\n",
    "all_eval_losses = []\n",
    "all_test_losses = []\n",
    "\n",
    "for seed in range(SEED, SEED+N_RUNS):\n",
    "    print(\"--------------------- BEGGINING NEW SEED:\", seed, \"----------------\")\n",
    "    df_eval, df_eval_out, df_test, df_test_out, losses4aggregation = run_single(seed)\n",
    "    all_train_losses.append(losses4aggregation['train'])\n",
    "    all_eval_losses.append(losses4aggregation['eval'])\n",
    "    all_test_losses.append(losses4aggregation['test'])\n",
    "    all_df_test.append(df_test)\n",
    "    df_list.append(df_test_out)  \n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)  \n",
    "all_train_losses = np.array(all_train_losses)\n",
    "all_eval_losses = np.array(all_eval_losses)\n",
    "all_test_losses = np.array(all_test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_rul_predictions(all_df_test, df_all, model_name, save=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the aggregated losses\n",
    "plot_aggregated_losses(all_train_losses, all_eval_losses, all_test_losses, model_name, save=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(f'test_scores/{model_name}_df_all.csv', index=False)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, best_idx = evaluate_per_unit_stored(df_all, all_df_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv4ml4pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
